{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-09T05:19:15.039558Z",
     "iopub.status.busy": "2021-11-09T05:19:15.038947Z",
     "iopub.status.idle": "2021-11-09T05:19:15.045587Z",
     "shell.execute_reply": "2021-11-09T05:19:15.044871Z",
     "shell.execute_reply.started": "2021-11-09T05:19:15.039509Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import argparse\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-09T05:14:13.682458Z",
     "iopub.status.busy": "2021-11-09T05:14:13.681690Z",
     "iopub.status.idle": "2021-11-09T05:14:13.692978Z",
     "shell.execute_reply": "2021-11-09T05:14:13.692264Z",
     "shell.execute_reply.started": "2021-11-09T05:14:13.682418Z"
    }
   },
   "outputs": [],
   "source": [
    "def CrossEntropy(outputs, targets, T=3):\n",
    "    log_softmax_outputs = F.log_softmax(outputs/T, dim=1)\n",
    "    softmax_targets = F.softmax(targets/T, dim=1)\n",
    "    return -(log_softmax_outputs * softmax_targets).sum(dim=1).mean()\n",
    "\n",
    "def get_orth_loss(net):\n",
    "    orth = 0\n",
    "    for layer in net.link:\n",
    "        para = list(layer.parameters())[0]\n",
    "        reshape_para = para.view(para.shape[0], -1).cuda()\n",
    "        ATA = torch.mm(reshape_para.t(), reshape_para).cuda()\n",
    "        O = torch.eye(ATA.shape[0]).cuda()\n",
    "        orth += ((ATA-O)**2).sum().cuda()\n",
    "        AAT = torch.mm(reshape_para, reshape_para.t()).cuda()\n",
    "        O = torch.eye(AAT.shape[0]).cuda()\n",
    "        orth += ((AAT - O)**2).sum().cuda()\n",
    "    return orth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T05:14:28.862783Z",
     "iopub.status.busy": "2021-11-09T05:14:28.862074Z",
     "iopub.status.idle": "2021-11-09T05:14:28.873841Z",
     "shell.execute_reply": "2021-11-09T05:14:28.872812Z",
     "shell.execute_reply.started": "2021-11-09T05:14:28.862721Z"
    }
   },
   "outputs": [],
   "source": [
    "class Cutout(object):\n",
    "    \"\"\"Randomly mask out one or more patches from an image.\n",
    "\n",
    "    Args:\n",
    "        n_holes (int): Number of patches to cut out of each image.\n",
    "        length (int): The length (in pixels) of each square patch.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_holes, length):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): Tensor image of size (C, H, W).\n",
    "        Returns:\n",
    "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
    "        \"\"\"\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "\n",
    "        for n in range(self.n_holes):\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "\n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.expand_as(img)\n",
    "        img = img * mask\n",
    "\n",
    "        return img\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T05:35:22.633201Z",
     "iopub.status.busy": "2021-11-09T05:35:22.632732Z",
     "iopub.status.idle": "2021-11-09T05:35:22.682401Z",
     "shell.execute_reply": "2021-11-09T05:35:22.681650Z",
     "shell.execute_reply.started": "2021-11-09T05:35:22.633164Z"
    }
   },
   "outputs": [],
   "source": [
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': './pretrain/resnet18-5c106cde.pth',\n",
    "    'resnet34': './pretrain/resnet34-333f7ec4.pth',\n",
    "    'resnet50': './pretrain/resnet50-19c8e357.pth',\n",
    "    'resnet101': './pretrain/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': './pretrain/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "\n",
    "class SepConv(nn.Module):\n",
    "\n",
    "    def __init__(self, channel_in, channel_out, kernel_size=3, stride=2, padding=1, affine=True):\n",
    "        #   depthwise and pointwise convolution, downsample by 2\n",
    "        super(SepConv, self).__init__()\n",
    "        self.op = nn.Sequential(\n",
    "            nn.Conv2d(channel_in, channel_in, kernel_size=kernel_size, stride=stride, padding=padding, groups=channel_in, bias=False),\n",
    "            nn.Conv2d(channel_in, channel_in, kernel_size=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(channel_in, affine=affine),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(channel_in, channel_in, kernel_size=kernel_size, stride=1, padding=padding, groups=channel_in, bias=False),\n",
    "            nn.Conv2d(channel_in, channel_out, kernel_size=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(channel_out, affine=affine),\n",
    "            nn.ReLU(inplace=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.op(x)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = conv1x1(inplanes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = conv1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=100, zero_init_residual=False, align=\"CONV\"):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.align = align\n",
    "        #   reduce the kernel-size and stride of ResNet on cifar datasets.\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        #   remove maxpooling layer for ResNet on cifar datasets.\n",
    "        #   self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.auxiliary1 = nn.Sequential(\n",
    "            SepConv(\n",
    "                channel_in=64 * block.expansion,\n",
    "                channel_out=128 * block.expansion\n",
    "            ),\n",
    "            SepConv(\n",
    "                channel_in=128 * block.expansion,\n",
    "                channel_out=256 * block.expansion\n",
    "            ),\n",
    "            SepConv(\n",
    "                channel_in=256 * block.expansion,\n",
    "                channel_out=512 * block.expansion\n",
    "            ),\n",
    "            nn.AvgPool2d(4, 4)\n",
    "        )\n",
    "\n",
    "        self.auxiliary2 = nn.Sequential(\n",
    "            SepConv(\n",
    "                channel_in=128 * block.expansion,\n",
    "                channel_out=256 * block.expansion,\n",
    "            ),\n",
    "            SepConv(\n",
    "                channel_in=256 * block.expansion,\n",
    "                channel_out=512 * block.expansion,\n",
    "            ),\n",
    "            nn.AvgPool2d(4, 4)\n",
    "        )\n",
    "        self.auxiliary3 = nn.Sequential(\n",
    "            SepConv(\n",
    "                channel_in=256 * block.expansion,\n",
    "                channel_out=512 * block.expansion,\n",
    "            ),\n",
    "            nn.AvgPool2d(4, 4)\n",
    "        )\n",
    "        self.auxiliary4 = nn.AvgPool2d(4, 4)\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.fc2 = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.fc3 = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.fc4 = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feature_list = []\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "        feature_list.append(x)\n",
    "        x = self.layer2(x)\n",
    "        feature_list.append(x)\n",
    "        x = self.layer3(x)\n",
    "        feature_list.append(x)\n",
    "        x = self.layer4(x)\n",
    "        feature_list.append(x)\n",
    "\n",
    "        out1_feature = self.auxiliary1(feature_list[0]).view(x.size(0), -1)\n",
    "        out2_feature = self.auxiliary2(feature_list[1]).view(x.size(0), -1)\n",
    "        out3_feature = self.auxiliary3(feature_list[2]).view(x.size(0), -1)\n",
    "        out4_feature = self.auxiliary4(feature_list[3]).view(x.size(0), -1)\n",
    "\n",
    "        out1 = self.fc1(out1_feature)\n",
    "        out2 = self.fc2(out2_feature)\n",
    "        out3 = self.fc3(out3_feature)\n",
    "        out4 = self.fc4(out4_feature)\n",
    "\n",
    "        return [out4, out3, out2, out1], [out4_feature, out3_feature, out2_feature, out1_feature]\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-09T05:35:31.316553Z",
     "iopub.status.busy": "2021-11-09T05:35:31.315916Z",
     "iopub.status.idle": "2021-11-09T05:35:31.325498Z",
     "shell.execute_reply": "2021-11-09T05:35:31.324668Z",
     "shell.execute_reply.started": "2021-11-09T05:35:31.316516Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#parser = argparse.ArgumentParser(description='Task-Oriented Feature Distillation. ')\n",
    "#parser.add_argument('--model', default=\"resnet18\", help=\"choose the student model\", type=str)\n",
    "#parser.add_argument('--dataset', default=\"cifar100\", type=str, help=\"cifar10/cifar100\")\n",
    "#parser.add_argument('--alpha', default=0.05, type=float)\n",
    "#parser.add_argument('--beta', default=0.03, type=float)\n",
    "#parser.add_argument('--l2', default=7e-3, type=float)\n",
    "#parser.add_argument('--teacher', default=\"resnet18\", type=str)\n",
    "#parser.add_argument('--t', default=3.0, type=float, help=\"temperature for logit distillation \")\n",
    "#args = parser.parse_args()\n",
    "#print(args)\n",
    "\n",
    "dataset = \"cifar10\"\n",
    "model = \"resnet18\"\n",
    "alpha = 0.05\n",
    "beta = 0.03\n",
    "l2 = 7e-3\n",
    "teacher_string = \"resnet18\"\n",
    "teacher = \"resnet18\"\n",
    "t = 3.0\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-09T05:36:30.346439Z",
     "iopub.status.busy": "2021-11-09T05:36:30.345916Z",
     "iopub.status.idle": "2021-11-09T05:36:32.298785Z",
     "shell.execute_reply": "2021-11-09T05:36:32.298062Z",
     "shell.execute_reply.started": "2021-11-09T05:36:30.346403Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "if not os.path.isdir('checkpoint'):\n",
    "    os.mkdir('checkpoint')\n",
    "\n",
    "                \n",
    "BATCH_SIZE = 128\n",
    "LR = 0.1\n",
    "\n",
    "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "print(\"Trying\")\n",
    "trainset, testset = None, None\n",
    "if dataset == 'cifar100':\n",
    "    trainset = torchvision.datasets.CIFAR100(\n",
    "        root='data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transform_train\n",
    "    )\n",
    "    testset = torchvision.datasets.CIFAR100(\n",
    "        root='data',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transform_test\n",
    "    )\n",
    "if dataset == 'cifar10':\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root='data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transform_train\n",
    "    )\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root='data',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transform_test\n",
    "    )\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "\n",
    "#   get the student model\n",
    "if model == \"resnet18\":\n",
    "    net = resnet18()\n",
    "\n",
    "#   get the teacher model\n",
    "if teacher_string == 'resnet18':\n",
    "    teacher = resnet18()\n",
    "\n",
    "# teacher.load_state_dict(torch.load(\"../input/d/jennyalk/teacherpytorch/teacher/\" + teacher_string + \".pth\"))\n",
    "#teacher.cuda()\n",
    "net = net.to(device)\n",
    "teacher = teacher.to(device)\n",
    "orthogonal_penalty = beta\n",
    "init = False\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, weight_decay=l2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-10-27T11:32:22.974681Z",
     "iopub.status.busy": "2021-10-27T11:32:22.973786Z",
     "iopub.status.idle": "2021-10-27T11:32:23.850255Z",
     "shell.execute_reply": "2021-10-27T11:32:23.848974Z",
     "shell.execute_reply.started": "2021-10-27T11:32:22.974629Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "mean_values = [0.4914, 0.4822, 0.4465]\n",
    "std_values = [0.2023, 0.1994, 0.2010]\n",
    "inv_transform = transforms.Normalize(\n",
    "    mean = [-m/s for m, s in zip(mean_values, std_values)],\n",
    "    std = [1/s for s in std_values])\n",
    "\n",
    "print(\"Checking\")\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "            length = len(trainloader)\n",
    "            inputs, labels = data\n",
    "\n",
    "            inverse_transform_image = inv_transform(inputs[0])\n",
    "            image = inverse_transform_image.numpy().transpose(1,2,0)\n",
    "            print(\"Label\")\n",
    "            print(labels[0])\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            #outputs, student_feature = net(inputs)\n",
    "            outputs_teacher, teacher_feature = teacher(inputs)\n",
    "            \n",
    "            _plot(model = net, cam_func = grad_cam, img= image, cls_true = outputs_teacher[0]) # Grad-Cam to show heatmap of \n",
    "            _plot(model = teacher, cam_func = grad_cam, img = image, cls_true = outputs_teacher[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-09T05:38:59.083424Z",
     "iopub.status.busy": "2021-11-09T05:38:59.083158Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    best_acc = 0\n",
    "    print(\"Start Training\")\n",
    "    for epoch in range(5):\n",
    "        print(\"Epoch = \" + str(epoch))\n",
    "        if epoch in [80, 160, 240]:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] /= 10\n",
    "        net.train()\n",
    "        sum_loss = 0.0\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            length = len(trainloader)\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs, student_feature = net(inputs)\n",
    "\n",
    "\n",
    "            #   get teacher results\n",
    "            with torch.no_grad():\n",
    "                teacher_logits, teacher_feature = teacher(inputs)\n",
    "\n",
    "            #   init the feature resizing layer depending on the feature size of students and teachers\n",
    "            #   a fully connected layer is used as feature resizing layer here\n",
    "            if not init:\n",
    "                teacher_feature_size = teacher_feature[0].size(1)\n",
    "                student_feature_size = student_feature[0].size(1)\n",
    "                num_auxiliary_classifier = len(teacher_logits)\n",
    "                link = []\n",
    "                for j in range(num_auxiliary_classifier):\n",
    "                    link.append(nn.Linear(student_feature_size, teacher_feature_size, bias=False))\n",
    "                net.link = nn.ModuleList(link)\n",
    "                net.cuda()\n",
    "                #   we redefine optimizer here so it can optimize the net.link layers.\n",
    "                optimizer = optim.SGD(net.parameters(), lr=LR, weight_decay=5e-4, momentum=0.9)\n",
    "                init = True\n",
    "\n",
    "            #   compute loss\n",
    "            loss = torch.FloatTensor([0.]).to(device)\n",
    "\n",
    "            #   Distillation Loss + Task Loss\n",
    "            for index in range(len(student_feature)):\n",
    "                student_feature[index] = net.link[index](student_feature[index])\n",
    "                #   task-oriented feature distillation loss\n",
    "                loss += torch.dist(student_feature[index], teacher_feature[index], p=2) * alpha\n",
    "                #   task loss (cross entropy loss for the classification task)\n",
    "                loss += criterion(outputs[index], labels)\n",
    "                \n",
    "                #grad-cam of student model on input image\n",
    "                #grad-cam of teacher model on input image\n",
    "                # loss-function (MSE) between \n",
    "                #   logit distillation loss, CrossEntropy implemented in utils.py.\n",
    "                loss += CrossEntropy(outputs[index], teacher_logits[index], 1 + (t / 250) * float(1 + epoch))\n",
    "\n",
    "            # Orthogonal Loss\n",
    "            for index in range(len(student_feature)):\n",
    "                weight = list(net.link[index].parameters())[0]\n",
    "                weight_trans = weight.permute(1, 0)\n",
    "                ones = torch.eye(weight.size(0)).cuda()\n",
    "                ones2 = torch.eye(weight.size(1)).cuda()\n",
    "                loss += torch.dist(torch.mm(weight, weight_trans), ones, p=2) * beta\n",
    "                loss += torch.dist(torch.mm(weight_trans, weight), ones2, p=2) * beta\n",
    "\n",
    "            sum_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total += float(labels.size(0))\n",
    "            _, predicted = torch.max(outputs[0].data, 1)\n",
    "            correct += float(predicted.eq(labels.data).cpu().sum())\n",
    "\n",
    "            if i % 200 == 0:\n",
    "                print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.2f%% '\n",
    "                      % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1),\n",
    "                         100 * correct / total))\n",
    "\n",
    "        print(\"Waiting Test!\")\n",
    "        with torch.no_grad():\n",
    "            correct = 0.0\n",
    "            total = 0.0\n",
    "            for data in testloader:\n",
    "                net.eval()\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs, feature = net(images)\n",
    "                _, predicted = torch.max(outputs[0].data, 1)\n",
    "                correct += float(predicted.eq(labels.data).cpu().sum())\n",
    "                total += float(labels.size(0))\n",
    "\n",
    "            print('Test Set AccuracyAcc:  %.4f%% ' % (100 * correct / total))\n",
    "            if correct / total > best_acc:\n",
    "                best_acc = correct / total\n",
    "                print(\"Best Accuracy Updated: \", best_acc * 100)\n",
    "                torch.save(net.state_dict(), \"./checkpoint/\" + model + \" - \" + str(epoch) + \".pth\")\n",
    "print(\"Training Finished, Best Accuracy is %.4f%%\" % (best_acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
